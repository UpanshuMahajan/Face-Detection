{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b15217a-fb7f-42cc-922f-6980ccb42852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image,ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bb612-6a30-4693-a689-295e1fbee59b",
   "metadata": {},
   "source": [
    "## Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da879e86-dde5-4ed1-b44e-588abd31d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Windows\\System32\\tensorflow-env\\lib\\site-packages\\cv2\\data\\\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.data.haarcascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8a246-e051-45f9-8fca-713dccd5e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_db():\n",
    "    face_clf = cv2.CascadeClassifier(r\"C:\\Windows\\System32\\tensorflow-env\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt2.xml\")\n",
    "\n",
    "\n",
    "    # Extracting images from camera\n",
    "    def face_data(image):\n",
    "        image_gry =  cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        face = face_clf.detectMultiScale(image_gry,1.3,5)\n",
    "        # setting scaling factor as 1.3 and minimum Neighbour as  5\n",
    "\n",
    "        if len(face) == 0:\n",
    "            return None\n",
    "            \n",
    "        if face_data is None:\n",
    "            return None\n",
    "        for (x,y,w,h)  in face:\n",
    "            sample = image[y:y+h,x:x+w]\n",
    "        return sample\n",
    "\n",
    "    vcap = cv2.VideoCapture(0)\n",
    "    user = 1\n",
    "    user_images = 0\n",
    "\n",
    "    # Opening the camera\n",
    "    while True:\n",
    "        r,frame = vcap.read()\n",
    "        if face_data(frame) is not None:\n",
    "            user_images = user_images + 1\n",
    "            detected_face = cv2.resize(face_data(frame), (200,200))\n",
    "            detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path = \"dataset/user.\"+ str(user) + \".\" + str(user_images) + \".\" + \"jpg\"\n",
    "            cv2.imwrite(file_name_path,detected_face)\n",
    "\n",
    "            # displaying the text \n",
    "            cv2.putText(detected_face,str(user_images),(50,50),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,20),2)\n",
    "            cv2.imshow(\"Detected Face\", detected_face)\n",
    "\n",
    "            # break condition \n",
    "            if (cv2.waitKey(1) == ord('x') & 0xff) or  int(user_images)== 200:\n",
    "                print(\"Exiting ...\")\n",
    "                break\n",
    "    vcap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Database of the User is generated....\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b3232-d0e0-4ee0-8bdc-0745ecf867c2",
   "metadata": {},
   "source": [
    "## Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7af67e-12f9-4cd5-9595-741e0f0b9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf(folder):\n",
    "    path = [os.path.join(folder,img_path)\n",
    "            for img_path in os.listdir(folder)\n",
    "           if img_path.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    faces = []\n",
    "    ids = []\n",
    "\n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imgArr = np.array(img,'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "\n",
    "\n",
    "        faces.append(imgArr)\n",
    "        ids.append(id)\n",
    "\n",
    "    ids = np.array(ids)\n",
    "    # Train and save classifier\n",
    "    clsf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clsf.train(faces,ids)\n",
    "    clsf.write(\"classifier.xml\")\n",
    "# clf('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f037-af0e-4757-9cd8-4a0f7f99e50e",
   "metadata": {},
   "source": [
    "## Detecting the Face and Draw a Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453e649-55f2-4464-8dff-d44b7b4182c2",
   "metadata": {},
   "source": [
    "## Recognizing the Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa72511-2fad-4272-b723-eb726c95798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundBox(img, classifier, scF, minN, color, txt, clf):\n",
    "    img_gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_ft = classifier.detectMultiScale(img_gry, scF, minN)\n",
    "    coords = []\n",
    "\n",
    "    for (x, y, w, h) in img_ft:\n",
    "        # Predict the face region\n",
    "        face = img_gry[y:y + h, x:x + w]\n",
    "        id, pred = clf.predict(face)\n",
    "\n",
    "        # Calculate confidence\n",
    "        confidence = int(100 * (1 - pred / 300))\n",
    "\n",
    "        # Determine label or unknown\n",
    "        if confidence > 77:\n",
    "            if id == 2:\n",
    "                label = \"Upanshu\"\n",
    "            else:\n",
    "                label = \"UNKNOWN\"\n",
    "            cv2.putText(img, label, (x, y - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, color, 1, cv2.LINE_8)\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        coords = [x, y, w, h]\n",
    "\n",
    "    return coords\n",
    "\n",
    "def rcz(img, clf, faceCascade):\n",
    "    coords = boundBox(img, faceCascade, 1.1, 10, (0, 255, 0), \"Face\", clf)\n",
    "    return img\n",
    "\n",
    "# Load face cascade and trained classifier\n",
    "faceCascade = cv2.CascadeClassifier(\n",
    "    r\"C:\\Windows\\System32\\tensorflow-env\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt2.xml\"\n",
    ")\n",
    "clsf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clsf.read('classifier.xml')\n",
    "\n",
    "# Open the video capture\n",
    "vcap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    r, img = vcap.read()\n",
    "    if not r:\n",
    "        print(\"Failed to capture video\")\n",
    "        break\n",
    "\n",
    "    img = rcz(img, clsf, faceCascade)\n",
    "    cv2.imshow(\"Face Detection\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "vcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51394361-9268-4034-a3d3-af7a9ff9c665",
   "metadata": {},
   "source": [
    "## Making the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bd9665-a2d0-4a9d-893d-b0013d344ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition system\")\n",
    "\n",
    "l1 = tk.Label(window, text=\"NAME\", font=(\"Helvetica\",20))\n",
    "\n",
    "l1.grid(column=0, row=0)\n",
    "\n",
    "t1 = tk.Entry(window, width=50, bd=5)\n",
    "t1.grid(column=1, row=0)\n",
    " \n",
    "\n",
    "def gen_db():\n",
    "    if t1.get() == \"\":\n",
    "        messagebox.showinfo('Result', 'Please provide the Name')\n",
    "    else:\n",
    "        # Connect to the database\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            passwd=\"\",\n",
    "            database=\"facedetct\",\n",
    "            use_pure=True\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "        mycursor.execute(\"SELECT MAX(id) FROM faces\")\n",
    "        myresult = mycursor.fetchall()\n",
    "        id = 1 if myresult[0][0] is None else myresult[0][0] + 1\n",
    "\n",
    "        # Insert new user\n",
    "        sql = \"INSERT INTO faces(id, Name) VALUES (%s, %s)\"\n",
    "        val = (id, t1.get())\n",
    "        mycursor.execute(sql, val)\n",
    "        mydb.commit()\n",
    "\n",
    "        face_clf = cv2.CascadeClassifier(r\"C:\\Windows\\System32\\tensorflow-env\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt2.xml\")\n",
    "\n",
    "        # Function to extract face data\n",
    "        def face_data(image):\n",
    "            image_gry = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            face = face_clf.detectMultiScale(image_gry, 1.3, 5)\n",
    "            if len(face) == 0:\n",
    "                return None\n",
    "            for (x, y, w, h) in face:\n",
    "                sample = image[y:y + h, x:x + w]\n",
    "            return sample\n",
    "\n",
    "        # Capture images\n",
    "        vcap = cv2.VideoCapture(0)\n",
    "        user_images = 0\n",
    "\n",
    "        while True:\n",
    "            r, frame = vcap.read()\n",
    "            if face_data(frame) is not None:\n",
    "                user_images += 1\n",
    "                detected_face = cv2.resize(face_data(frame), (200, 200))\n",
    "                detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Use the unique user ID for file naming\n",
    "                file_name_path = f\"dataset/user.{id}.{user_images}.jpg\"\n",
    "                cv2.imwrite(file_name_path, detected_face)\n",
    "\n",
    "                cv2.putText(detected_face, str(user_images), (50, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 20), 2)\n",
    "                cv2.imshow(\"Detected Face\", detected_face)\n",
    "\n",
    "                # Stop capturing after 200 images or if 'x' is pressed\n",
    "                if cv2.waitKey(1) == ord('x') or user_images == 200:\n",
    "                    print(\"Exiting ...\")\n",
    "                    break\n",
    "\n",
    "        vcap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Database of the User is generated....\")\n",
    "        messagebox.showinfo('Result', 'Database Generated...')\n",
    "\n",
    "\n",
    "\n",
    "# b1 = tk.Button(window, text=\"Generate dataset\", font=(\"Algerian\",20), bg=\"pink\", fg=\"black\",command = gen_db)\n",
    "b1 = tk.Button(\n",
    "    window, \n",
    "    text=\"Generate dataset\", \n",
    "    font=(\"Comic Sans MS\", 10, \"bold\"), \n",
    "    bg=\"black\", \n",
    "    fg=\"white\", \n",
    "    activebackground=\"white\", \n",
    "    activeforeground=\"black\",\n",
    "    width=20,   \n",
    "    height=2,\n",
    "    command=gen_db,\n",
    "    bd=6,  \n",
    "    relief=\"raised\" \n",
    ")\n",
    "b1.grid(column=0, row=4) \n",
    "\n",
    "def clf():\n",
    "    folder = r'C:\\Users\\acer\\Desktop\\learn\\Sem7\\Major Project\\dataset'\n",
    "    path = [os.path.join(folder,img_path)\n",
    "            for img_path in os.listdir(folder)\n",
    "           if img_path.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    faces = []\n",
    "    ids = []\n",
    "\n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imgArr = np.array(img,'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "\n",
    "\n",
    "        faces.append(imgArr)\n",
    "        ids.append(id)\n",
    "\n",
    "    ids = np.array(ids)\n",
    "    # Train and save classifier\n",
    "    clsf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clsf.train(faces,ids)\n",
    "    clsf.write(\"classifier.xml\")\n",
    "    messagebox.showinfo('Result','Training Completed...')\n",
    "\n",
    "# b2 = tk.Button(window, text=\"Train\", font=(\"Algerian\",20),bg=\"orange\",fg=\"red\",command = clf)\n",
    "b2 = tk.Button(\n",
    "    window, \n",
    "    text=\"Train\", \n",
    "    font=(\"Comic Sans MS\", 10, \"bold\"), \n",
    "    bg=\"black\", \n",
    "    fg=\"white\", \n",
    "    activebackground=\"white\", \n",
    "    activeforeground=\"black\", \n",
    "    command=clf,\n",
    "    width=20,\n",
    "    height=2,\n",
    "    bd=6,  \n",
    "    relief=\"raised\" \n",
    ")\n",
    "\n",
    "\n",
    "b2.grid(column=2, row=4)\n",
    "\n",
    "def result():\n",
    "    def boundBox(img, classifier, scF, minN, color, txt, clf):\n",
    "        img_gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_ft = classifier.detectMultiScale(img_gry, scF, minN)\n",
    "        coords = []\n",
    "    \n",
    "        for (x, y, w, h) in img_ft:\n",
    "            # Predict the face region\n",
    "            face = img_gry[y:y + h, x:x + w]\n",
    "            id, pred = clf.predict(face)\n",
    "    \n",
    "            # Calculate confidence\n",
    "            confidence = int(100 * (1 - pred / 300))\n",
    "\n",
    "            mydb = mysql.connector.connect(\n",
    "                host = \"localhost\",\n",
    "                user = \"root\",\n",
    "                passwd = \"\",\n",
    "                database = \"facedetct\",\n",
    "                use_pure=True\n",
    "                \n",
    "            )\n",
    "            mycursor = mydb.cursor()\n",
    "            mycursor.execute(\"SELECT name from faces where id =\"+ str(id))\n",
    "            result = mycursor.fetchall()\n",
    "            if result:\n",
    "                count = ''.join(result[0])  \n",
    "            else:\n",
    "                count = \"Unknown\"\n",
    "            count = ''+ ''.join(count)\n",
    "            \n",
    "            # Determine label or unknown\n",
    "            if confidence > 77:\n",
    "                label = count\n",
    "            else:\n",
    "                label = \"UNKNOWN\"\n",
    "            cv2.putText(img, label, (x, y - 5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, color, 1, cv2.LINE_8)\n",
    "    \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            coords = [x, y, w, h]\n",
    "    \n",
    "        return coords\n",
    "\n",
    "    def rcz(img, clf, faceCascade):\n",
    "        coords = boundBox(img, faceCascade, 1.1, 10, (0, 255, 0), \"Face\", clf)\n",
    "        return img\n",
    "    \n",
    "    # Load face cascade and trained classifier\n",
    "    faceCascade = cv2.CascadeClassifier(\n",
    "        r\"C:\\Windows\\System32\\tensorflow-env\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt2.xml\"\n",
    "    )\n",
    "    clsf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clsf.read('classifier.xml')\n",
    "    \n",
    "    # Open the video capture\n",
    "    vcap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        r, img = vcap.read()\n",
    "        if not r:\n",
    "            print(\"Failed to capture video\")\n",
    "            break\n",
    "    \n",
    "        img = rcz(img, clsf, faceCascade)\n",
    "        cv2.imshow(\"Face Detection\", img)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "            break\n",
    "    \n",
    "    vcap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "b3 = tk.Button(\n",
    "    window, \n",
    "    text=\"Detect the faces\", \n",
    "    font=(\"Comic Sans MS\", 10, \"bold\"), \n",
    "    bg=\"black\", \n",
    "    fg=\"white\", \n",
    "    activebackground=\"white\", \n",
    "    activeforeground=\"black\", \n",
    "    command=result,\n",
    "    width=20,   \n",
    "    height=2,\n",
    "    bd=6,  \n",
    "    relief=\"raised\" \n",
    ")\n",
    "\n",
    "b3.grid(column=1, row=4)\n",
    " # b3 = tk.Button(window, text=\"Detect the faces\", font=(\"Algerian\",20), bg=\"green\", fg=\"orange\",command = result)\n",
    "\n",
    "b1.grid(column=0, row=4, padx=5, pady=5)\n",
    "b2.grid(column=2, row=4, padx=5, pady=5)\n",
    "b3.grid(column=1, row=4, padx=5, pady=5)\n",
    "\n",
    " \n",
    "window.geometry(\"690x150\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93a5bd-bfba-46ae-95eb-60f39480f37c",
   "metadata": {},
   "source": [
    "## Integrating with MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2326f5-7d92-471f-b73e-adf5f531b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection successful!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        passwd=\"\",\n",
    "        use_pure=True\n",
    "    )\n",
    "    if mydb.is_connected():\n",
    "        print(\"MySQL connection successful!\")\n",
    "except Error as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"CREATE DATABASE faceDetct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4af7c15b-46b9-4149-bb63-c5aec7bdcf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('facedetct',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('phpmyadmin',)\n",
      "('test',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW DATABASES\")\n",
    "for i in mycursor:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78bb62d-5658-4fb3-b965-83cbae97a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.database = \"faceDetct\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d5d5e4-c910-46eb-877b-109b79127ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'faces' created successfully!\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"USE faceDetct\")\n",
    "mycursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS faces (\n",
    "            id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "            name VARCHAR(20)\n",
    "        )\n",
    "    \"\"\")\n",
    "print(\"Table 'faces' created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
